{
    "metrics": {
        "retrieval": [
            0.979381443298969,
            0.8969072164948454,
            0.8969072164948454,
            0.8350515463917526
        ],
        "scoring": [
            0.8553115743905219,
            0.8988351560719982,
            0.9916068580542264,
            0.6289530644793802,
            0.6235040726817042,
            0.6184951013898382,
            0.6192113807245386
        ],
        "prediction": [
            0.5773195876288659,
            0.7731958762886598
        ]
    },
    "configs": {
        "retrieval": [
            {
                "module_type": "vector_db",
                "metric_name": "retrieval_hit_rate",
                "metric_value": 0.979381443298969,
                "k": 10,
                "model_name": "deepvk/USER-bge-m3"
            },
            {
                "module_type": "vector_db",
                "metric_name": "retrieval_hit_rate",
                "metric_value": 0.8969072164948454,
                "k": 10,
                "model_name": "intfloat/multilingual-e5-base"
            },
            {
                "module_type": "vector_db",
                "metric_name": "retrieval_hit_rate",
                "metric_value": 0.8969072164948454,
                "k": 10,
                "model_name": "sergeyzh/LaBSE-ru-turbo"
            },
            {
                "module_type": "vector_db",
                "metric_name": "retrieval_hit_rate",
                "metric_value": 0.8350515463917526,
                "k": 10,
                "model_name": "deepvk/USER-base"
            }
        ],
        "scoring": [
            {
                "module_type": "knn",
                "metric_name": "scoring_roc_auc",
                "metric_value": 0.8553115743905219,
                "k": 1
            },
            {
                "module_type": "knn",
                "metric_name": "scoring_roc_auc",
                "metric_value": 0.8988351560719982,
                "k": 3
            },
            {
                "module_type": "linear",
                "metric_name": "scoring_roc_auc",
                "metric_value": 0.9916068580542264
            },
            {
                "module_type": "dnnc",
                "metric_name": "scoring_roc_auc",
                "metric_value": 0.6289530644793802,
                "model_name": "mixedbread-ai/mxbai-embed-large-v1",
                "k": 10
            },
            {
                "module_type": "dnnc",
                "metric_name": "scoring_roc_auc",
                "metric_value": 0.6235040726817042,
                "model_name": "avsolatorio/GIST-large-Embedding-v0",
                "k": 10
            },
            {
                "module_type": "dnnc",
                "metric_name": "scoring_roc_auc",
                "metric_value": 0.6184951013898382,
                "model_name": "llmrails/ember-v1",
                "k": 10
            },
            {
                "module_type": "dnnc",
                "metric_name": "scoring_roc_auc",
                "metric_value": 0.6192113807245386,
                "model_name": "BAAI/bge-large-en-v1.5",
                "k": 10
            }
        ],
        "prediction": [
            {
                "module_type": "threshold",
                "metric_name": "prediction_accuracy",
                "metric_value": 0.5773195876288659,
                "single_thresh": true
            },
            {
                "module_type": "argmax",
                "metric_name": "prediction_accuracy",
                "metric_value": 0.7731958762886598
            }
        ]
    }
}