{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpler Pipeline Optimization Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate full-fledged optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 57)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autointent.context.data_handler import Dataset\n",
    "from autointent.context.utils import load_data\n",
    "\n",
    "scoring_dataset = load_data(\"./data/train_data.json\")\n",
    "prediction_dataset = load_data(\"./data/test_data.json\")\n",
    "len(scoring_dataset.utterances), len(prediction_dataset.utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autointent.pipeline.optimization import PipelineOptimizer\n",
    "\n",
    "config = {\n",
    "    \"nodes\": [\n",
    "        {\n",
    "            \"node_type\": \"scoring\",\n",
    "            \"metric\": \"scoring_roc_auc\",\n",
    "            \"search_space\": [\n",
    "                {\"module_type\": \"knn\", \"k\": [5, 10], \"weights\": [\"uniform\", \"distance\", \"closest\"], \"model_name\": [\"avsolatorio/GIST-small-Embedding-v0\"]},\n",
    "                {\"module_type\": \"linear\", \"model_name\": [\"avsolatorio/GIST-small-Embedding-v0\"]},\n",
    "                # {\n",
    "                #     \"module_type\": \"dnnc\",\n",
    "                #     \"cross_encoder_name\": [\"cross-encoder/ms-marco-MiniLM-L-6-v2\", \"avsolatorio/GIST-small-Embedding-v0\"],\n",
    "                #     \"search_model_name\": [\"avsolatorio/GIST-small-Embedding-v0\"],\n",
    "                #     \"k\": [1, 3],\n",
    "                #     \"train_head\": [False, True],\n",
    "                # },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"node_type\": \"prediction\",\n",
    "            \"metric\": \"prediction_accuracy\",\n",
    "            \"search_space\": [\n",
    "                {\"module_type\": \"threshold\", \"thresh\": [0.5]},\n",
    "                {\"module_type\": \"tunable\"},\n",
    "                # {\"module_type\": \"argmax\"},\n",
    "                # {\"module_type\": \"jinoos\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipeline_optimizer = PipelineOptimizer.from_dict_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Configure Your Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autointent.configs.optimization_cli import LoggingConfig, VectorIndexConfig, EmbedderConfig\n",
    "from pathlib import Path\n",
    "\n",
    "pipeline_optimizer.set_config(LoggingConfig(run_name=\"sweet_cucumber\", dirpath=Path.cwd(), dump_modules=True, clear_ram=True))\n",
    "pipeline_optimizer.set_config(VectorIndexConfig(db_dir=Path(\"./my_vector_db\").resolve(), device=\"cuda\"))\n",
    "pipeline_optimizer.set_config(EmbedderConfig(batch_size=16, max_length=32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 13:10:03,339] A new study created in memory with name: no-name-85c71fe7-cc94-448b-a9a0-46470688fb6b\n"
     ]
    }
   ],
   "source": [
    "context = pipeline_optimizer.optimize_from_dataset(scoring_dataset, prediction_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autointent.pipeline.inference import InferencePipeline\n",
    "\n",
    "inference_pipeline = InferencePipeline.from_context(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_pipeline.predict([\"hello world\", \"what is the eagles address\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No modules dumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "! rm -rf sweet_cucumber*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer.set_config(LoggingConfig(dump_modules=False, clear_ram=False))\n",
    "pipeline_optimizer.set_config(VectorIndexConfig(db_dir=Path(\"./my_vector_db\").resolve(), device=\"cuda\"))\n",
    "pipeline_optimizer.set_config(EmbedderConfig(batch_size=16, max_length=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = pipeline_optimizer.optimize_from_dataset(scoring_dataset, prediction_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline = InferencePipeline.from_context(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_pipeline.predict([\"hello world\", \"what is the eagles address\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autointent-D7M6VOhJ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
