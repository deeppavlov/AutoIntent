{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autointent.nodes.optimization import NodeOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autointent import Context\n",
    "from autointent.pipeline.optimization.utils import get_run_name, load_data, get_db_dir\n",
    "\n",
    "\n",
    "run_name = get_run_name(\"multiclass-cpu\")\n",
    "db_dir = get_db_dir(\"\", run_name)\n",
    "\n",
    "data = load_data(\"/home/voorhs/repos/AutoIntent/tests/minimal_optimization/data/clinc_subset.json\", multilabel=False)\n",
    "context = Context(\n",
    "    multiclass_intent_records=data,\n",
    "    multilabel_utterance_records=[],\n",
    "    test_utterance_records=[],\n",
    "    device=\"cpu\",\n",
    "    mode=\"multiclass_as_multilabel\",\n",
    "    multilabel_generation_config=\"\",\n",
    "    db_dir=db_dir,\n",
    "    regex_sampling=0,\n",
    "    seed=0,\n",
    "    dump_dir=\"modules_dumps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_optimizer_config = {\n",
    "    'metric': 'retrieval_hit_rate_intersecting',\n",
    "    'node_type': 'retrieval',\n",
    "    'search_space': [\n",
    "        {\n",
    "            'k': [10],\n",
    "            'model_name': ['deepvk/USER-bge-m3'],\n",
    "            'module_type': 'vector_db'\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_optimizer = NodeOptimizer.from_dict_config(retrieval_optimizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_optimizer.fit(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_optimizer_config = {\n",
    "    'metric': 'scoring_roc_auc',\n",
    "    'node_type': 'scoring',\n",
    "    'search_space': [\n",
    "        {\n",
    "            'k': [3],\n",
    "            'module_type': 'knn',\n",
    "            'weights': ['uniform', 'distance', 'closest']\n",
    "        },\n",
    "        {\n",
    "            'module_type': 'linear'\n",
    "        },\n",
    "        {\n",
    "            \"module_type\": \"mlknn\",\n",
    "            \"k\": [5]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_optimizer = NodeOptimizer.from_dict_config(scoring_optimizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_optimizer.fit(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_optimizer_config = {\n",
    "    'metric': 'prediction_accuracy',\n",
    "    'node_type': 'prediction',\n",
    "    'search_space': [\n",
    "        {\n",
    "            'module_type': 'threshold',\n",
    "            'thresh': [0.5]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_optimizer = NodeOptimizer.from_dict_config(prediction_optimizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_optimizer.fit(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics': {'regexp': [],\n",
       "  'retrieval': [1.0],\n",
       "  'scoring': [1.0, 1.0, 1.0, 1.0],\n",
       "  'prediction': [0.8333333333333334]},\n",
       " 'configs': {'regexp': [],\n",
       "  'retrieval': [{'module_type': 'vector_db',\n",
       "    'module_params': {'k': 10, 'model_name': 'deepvk/USER-bge-m3'},\n",
       "    'metric_name': 'retrieval_hit_rate_intersecting',\n",
       "    'metric_value': 1.0}],\n",
       "  'scoring': [{'module_type': 'knn',\n",
       "    'module_params': {'k': 3, 'weights': 'uniform'},\n",
       "    'metric_name': 'scoring_roc_auc',\n",
       "    'metric_value': 1.0},\n",
       "   {'module_type': 'knn',\n",
       "    'module_params': {'k': 3, 'weights': 'distance'},\n",
       "    'metric_name': 'scoring_roc_auc',\n",
       "    'metric_value': 1.0},\n",
       "   {'module_type': 'knn',\n",
       "    'module_params': {'k': 3, 'weights': 'closest'},\n",
       "    'metric_name': 'scoring_roc_auc',\n",
       "    'metric_value': 1.0},\n",
       "   {'module_type': 'linear',\n",
       "    'module_params': {},\n",
       "    'metric_name': 'scoring_roc_auc',\n",
       "    'metric_value': 1.0}],\n",
       "  'prediction': [{'module_type': 'threshold',\n",
       "    'module_params': {'thresh': 0.5},\n",
       "    'metric_name': 'prediction_accuracy',\n",
       "    'metric_value': 0.8333333333333334}]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.optimization_info.dump_evaluation_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autointent.nodes import InferenceNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== vector_db ====\n",
      "\n",
      "[[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0]] [np.float32(0.477605), np.float32(0.49597514), np.float32(0.50022346), np.float32(0.5128485), np.float32(0.55573064), np.float32(0.5758226), np.float32(0.58933824), np.float32(0.6130637), np.float32(0.6174678), np.float32(0.63502705)] ['please set an alarm for mid day', 'make sure my alarm is set for three thirty in the morning', 'have an alarm set for three in the morning', 'wake me up at noon tomorrow', 'i think my account is blocked but i do not know the reason', 'can you tell me why is my bank account frozen', 'can i make a reservation for redrobin', 'why is there a hold on my capital one checking account', 'why is there a hold on my american saving bank account', 'are reservations taken at redrobin']\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "\n",
    "for trial in context.optimization_info.trials.retrieval:\n",
    "    print(f\"\\n==== {trial.module_type} ====\\n\")\n",
    "    config = dict(\n",
    "        node_type=\"retrieval\",\n",
    "        module_type=trial.module_type,\n",
    "        module_config=trial.module_params,\n",
    "        load_path=trial.module_dump_dir,\n",
    "    )\n",
    "    node = InferenceNode(**config)\n",
    "    labels, distances, texts = node.module.predict([\"hello\", \"world\"])\n",
    "    print(labels[0], distances[0], texts[0])\n",
    "    node.module.clear_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== knn ====\n",
      "\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "==== knn ====\n",
      "\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         0.99999998]]\n",
      "\n",
      "==== knn ====\n",
      "\n",
      "[[0.         0.         0.7611975 ]\n",
      " [0.         0.         0.73897344]]\n",
      "\n",
      "==== linear ====\n",
      "\n",
      "[[0.27486506 0.31681463 0.37459106]\n",
      " [0.2769358  0.31536099 0.37366978]]\n",
      "\n",
      "==== mlknn ====\n",
      "\n",
      "[[0.08860759 0.1147541  0.79545455]\n",
      " [0.08860759 0.1147541  0.79545455]]\n"
     ]
    }
   ],
   "source": [
    "for trial in context.optimization_info.trials.scoring:\n",
    "    print(f\"\\n==== {trial.module_type} ====\\n\")\n",
    "    config = dict(\n",
    "        node_type=\"scoring\",\n",
    "        module_type=trial.module_type,\n",
    "        module_config=trial.module_params,\n",
    "        load_path=trial.module_dump_dir,\n",
    "    )\n",
    "    node = InferenceNode(**config)\n",
    "    scores = node.module.predict([\"hello\", \"world\"])\n",
    "    print(scores)\n",
    "    node.module.clear_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_config = dict(\n",
    "    node_type=\"prediction\",\n",
    "    module_type=\"threshold\",\n",
    "    module_config={\"thresh\": 0.5},\n",
    "    load_path=\".\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = InferenceNode(**prediction_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.module.predict(context, ...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autointent-D7M6VOhJ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
