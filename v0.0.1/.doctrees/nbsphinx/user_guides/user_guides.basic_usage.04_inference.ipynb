{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688e1503",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Inference Pipeline\n",
    "\n",
    "After you configured optimal pipeline with AutoIntent, you probably want to test its power on some new data! There are several options:\n",
    "\n",
    "- use it right after optimization\n",
    "- save to file system and then load\n",
    "\n",
    "## Right After\n",
    "\n",
    "Here's the basic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87186c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T23:21:11.176548Z",
     "iopub.status.busy": "2024-12-17T23:21:11.176347Z",
     "iopub.status.idle": "2024-12-17T23:22:35.575673Z",
     "shell.execute_reply": "2024-12-17T23:22:35.574789Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/.cache/pypoetry/virtualenvs/autointent-FDypUDHQ-py3.10/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autointent import Dataset, Pipeline\n",
    "\n",
    "dataset = Dataset.from_hub(\"AutoIntent/clinc150_subset\")\n",
    "pipeline = Pipeline.default_optimizer(multilabel=False)\n",
    "context = pipeline.fit(dataset)\n",
    "pipeline.predict([\"hello, world!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e92e84",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "There are several caveats.\n",
    "\n",
    "1. **Save vector databse.**\n",
    "\n",
    "When customizing configuration of pipeline optimization, you need to ensure that the option `save_db` of [VectorIndexConfig](../autoapi/autointent/configs/VectorIndexConfig.html#autointent.configs.VectorIndexConfig) is set to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c325d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T23:22:35.578847Z",
     "iopub.status.busy": "2024-12-17T23:22:35.578270Z",
     "iopub.status.idle": "2024-12-17T23:22:35.582385Z",
     "shell.execute_reply": "2024-12-17T23:22:35.581841Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import VectorIndexConfig\n",
    "\n",
    "# isn't compatible with \"right-after-optimization\" inference\n",
    "vector_index_config = VectorIndexConfig(save_db=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ccbabb",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "2. **RAM usage.**\n",
    "\n",
    "You can optimize RAM usage by saving all modules to file system. Just set the following options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c024324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T23:22:35.584340Z",
     "iopub.status.busy": "2024-12-17T23:22:35.584141Z",
     "iopub.status.idle": "2024-12-17T23:22:35.587369Z",
     "shell.execute_reply": "2024-12-17T23:22:35.586823Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import LoggingConfig\n",
    "\n",
    "logging_config = LoggingConfig(dump_modules=True, clear_ram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87beaa62",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Load from File System\n",
    "\n",
    "Firstly, your auto-configuration run should dump modules into file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43186c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T23:22:35.589363Z",
     "iopub.status.busy": "2024-12-17T23:22:35.588977Z",
     "iopub.status.idle": "2024-12-17T23:22:38.648352Z",
     "shell.execute_reply": "2024-12-17T23:22:38.647614Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from autointent import Dataset, Pipeline\n",
    "from autointent.configs import LoggingConfig, VectorIndexConfig\n",
    "\n",
    "dataset = Dataset.from_hub(\"AutoIntent/clinc150_subset\")\n",
    "pipeline = Pipeline.default_optimizer(multilabel=False)\n",
    "dump_dir = Path(\"my_dumps\")\n",
    "pipeline.set_config(LoggingConfig(dump_dir=dump_dir, dump_modules=True, clear_ram=True))\n",
    "pipeline.set_config(VectorIndexConfig(save_db=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513c86df",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Secondly, after optimization finished, you need to save the auto-configuration results to file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c3a40e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T23:22:38.650841Z",
     "iopub.status.busy": "2024-12-17T23:22:38.650428Z",
     "iopub.status.idle": "2024-12-17T23:24:12.029003Z",
     "shell.execute_reply": "2024-12-17T23:24:12.028288Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "context = pipeline.fit(dataset)\n",
    "context.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de50cffc",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "This command saves all results to the run's directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b81455d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T23:24:12.031533Z",
     "iopub.status.busy": "2024-12-17T23:24:12.031314Z",
     "iopub.status.idle": "2024-12-17T23:24:12.036415Z",
     "shell.execute_reply": "2024-12-17T23:24:12.035760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/runner/work/AutoIntent/AutoIntent/docs/source/user_guides/runs/dull_duck_12-17-2024_23-22-38')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_directory = context.logging_config.dirpath\n",
    "run_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c943c20",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "After that, you can load pipeline for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd0c0219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T23:24:12.038625Z",
     "iopub.status.busy": "2024-12-17T23:24:12.038243Z",
     "iopub.status.idle": "2024-12-17T23:24:14.589155Z",
     "shell.execute_reply": "2024-12-17T23:24:14.588442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pipeline = Pipeline.load(run_directory)\n",
    "loaded_pipeline.predict([\"hello, world!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692e741",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## That's all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aca7ec16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T23:24:14.591749Z",
     "iopub.status.busy": "2024-12-17T23:24:14.591250Z",
     "iopub.status.idle": "2024-12-17T23:24:15.783607Z",
     "shell.execute_reply": "2024-12-17T23:24:15.782995Z"
    }
   },
   "outputs": [],
   "source": [
    "# [you didn't see it]\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(dump_dir)\n",
    "\n",
    "for file in Path.cwd().glob(\"vector_db*\"):\n",
    "    shutil.rmtree(file)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
