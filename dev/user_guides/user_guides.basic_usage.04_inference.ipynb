{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289ca81d",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Inference Pipeline\n",
    "\n",
    "After you configured optimal pipeline with AutoIntent, you probably want to test its power on some new data! There are several options:\n",
    "\n",
    "- use it right after optimization\n",
    "- save to file system and then load\n",
    "\n",
    "## Right After\n",
    "\n",
    "Here's the basic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e36acc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:51:35.333389Z",
     "iopub.status.busy": "2024-12-18T11:51:35.333192Z",
     "iopub.status.idle": "2024-12-18T11:52:53.383404Z",
     "shell.execute_reply": "2024-12-18T11:52:53.382737Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/.cache/pypoetry/virtualenvs/autointent-FDypUDHQ-py3.10/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autointent import Dataset, Pipeline\n",
    "\n",
    "dataset = Dataset.from_hub(\"AutoIntent/clinc150_subset\")\n",
    "pipeline = Pipeline.default_optimizer(multilabel=False)\n",
    "context = pipeline.fit(dataset)\n",
    "pipeline.predict([\"hello, world!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34073a2",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "There are several caveats.\n",
    "\n",
    "1. **Save vector databse.**\n",
    "\n",
    "When customizing configuration of pipeline optimization, you need to ensure that the option `save_db` of [VectorIndexConfig](../autoapi/autointent/configs/VectorIndexConfig.html#autointent.configs.VectorIndexConfig) is set to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13d82d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:52:53.386105Z",
     "iopub.status.busy": "2024-12-18T11:52:53.385381Z",
     "iopub.status.idle": "2024-12-18T11:52:53.389053Z",
     "shell.execute_reply": "2024-12-18T11:52:53.388488Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import VectorIndexConfig\n",
    "\n",
    "# isn't compatible with \"right-after-optimization\" inference\n",
    "vector_index_config = VectorIndexConfig(save_db=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63fb066",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "2. **RAM usage.**\n",
    "\n",
    "You can optimize RAM usage by saving all modules to file system. Just set the following options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99027f8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:52:53.391099Z",
     "iopub.status.busy": "2024-12-18T11:52:53.390705Z",
     "iopub.status.idle": "2024-12-18T11:52:53.393703Z",
     "shell.execute_reply": "2024-12-18T11:52:53.393177Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import LoggingConfig\n",
    "\n",
    "logging_config = LoggingConfig(dump_modules=True, clear_ram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da999552",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Load from File System\n",
    "\n",
    "Firstly, your auto-configuration run should dump modules into file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e6b94a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:52:53.395697Z",
     "iopub.status.busy": "2024-12-18T11:52:53.395314Z",
     "iopub.status.idle": "2024-12-18T11:52:55.820697Z",
     "shell.execute_reply": "2024-12-18T11:52:55.819994Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from autointent import Dataset, Pipeline\n",
    "from autointent.configs import LoggingConfig, VectorIndexConfig\n",
    "\n",
    "dataset = Dataset.from_hub(\"AutoIntent/clinc150_subset\")\n",
    "pipeline = Pipeline.default_optimizer(multilabel=False)\n",
    "dump_dir = Path(\"my_dumps\")\n",
    "pipeline.set_config(LoggingConfig(dump_dir=dump_dir, dump_modules=True, clear_ram=True))\n",
    "pipeline.set_config(VectorIndexConfig(save_db=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034d568",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Secondly, after optimization finished, you need to save the auto-configuration results to file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffec993b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:52:55.823082Z",
     "iopub.status.busy": "2024-12-18T11:52:55.822870Z",
     "iopub.status.idle": "2024-12-18T11:54:22.161013Z",
     "shell.execute_reply": "2024-12-18T11:54:22.160312Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "context = pipeline.fit(dataset)\n",
    "context.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66912e0",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "This command saves all results to the run's directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73324d50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:54:22.163527Z",
     "iopub.status.busy": "2024-12-18T11:54:22.163109Z",
     "iopub.status.idle": "2024-12-18T11:54:22.167564Z",
     "shell.execute_reply": "2024-12-18T11:54:22.167049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/runner/work/AutoIntent/AutoIntent/docs/source/user_guides/runs/dull_duck_12-18-2024_11-52-55')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_directory = context.logging_config.dirpath\n",
    "run_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcdc65e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "After that, you can load pipeline for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ba93ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:54:22.169525Z",
     "iopub.status.busy": "2024-12-18T11:54:22.169160Z",
     "iopub.status.idle": "2024-12-18T11:54:23.820126Z",
     "shell.execute_reply": "2024-12-18T11:54:23.819392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pipeline = Pipeline.load(run_directory)\n",
    "loaded_pipeline.predict([\"hello, world!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb348423",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## That's all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e027b14b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T11:54:23.822227Z",
     "iopub.status.busy": "2024-12-18T11:54:23.822017Z",
     "iopub.status.idle": "2024-12-18T11:54:24.878580Z",
     "shell.execute_reply": "2024-12-18T11:54:24.877928Z"
    }
   },
   "outputs": [],
   "source": [
    "# [you didn't see it]\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(dump_dir)\n",
    "\n",
    "for file in Path.cwd().glob(\"vector_db*\"):\n",
    "    shutil.rmtree(file)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
