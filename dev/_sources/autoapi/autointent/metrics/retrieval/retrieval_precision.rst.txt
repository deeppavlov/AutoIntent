autointent.metrics.retrieval.retrieval_precision
================================================

.. py:function:: autointent.metrics.retrieval.retrieval_precision(query_labels, candidates_labels, k = None)

   Calculate the precision at position k.

   Precision at position :math:`k` is calculated as:

   .. math::

       \text{Precision@k} = \frac{1}{N} \sum_{i=1}^N \frac{|y_{\text{query},i} \cap
       y_{\text{candidates},i}^{(1:k)}|}{k}

   where:
   - :math:`N` is the total number of queries,
   - :math:`y_{\text{query},i}` is the true label for the :math:`i`-th query,
   - :math:`y_{\text{candidates},i}^{(1:k)}` is the set of top-k predicted labels for the :math:`i`-th query.

   :param query_labels: For each query, this list contains its class labels
   :param candidates_labels: For each query, these lists contain class labels of items ranked by a retrieval model
    (from most to least relevant)
   :param k: Number of top items to consider for each query
   :return: Score of the retrieval metric

