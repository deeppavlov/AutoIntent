{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e33d2af",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Inference Pipeline\n",
    "\n",
    "After you configured optimal pipeline with AutoIntent, you probably want to test its power on some new data! There are several options:\n",
    "\n",
    "- use it right after optimization\n",
    "- save to file system and then load\n",
    "\n",
    "## Right After\n",
    "\n",
    "Here's the basic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc97de24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:22:19.738069Z",
     "iopub.status.busy": "2024-12-18T13:22:19.737865Z",
     "iopub.status.idle": "2024-12-18T13:23:25.180355Z",
     "shell.execute_reply": "2024-12-18T13:23:25.179506Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/.cache/pypoetry/virtualenvs/autointent-FDypUDHQ-py3.10/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autointent import Dataset, Pipeline\n",
    "\n",
    "dataset = Dataset.from_hub(\"AutoIntent/clinc150_subset\")\n",
    "pipeline = Pipeline.default_optimizer(multilabel=False)\n",
    "context = pipeline.fit(dataset)\n",
    "pipeline.predict([\"hello, world!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3929ac35",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "There are several caveats.\n",
    "\n",
    "1. **Save vector databse.**\n",
    "\n",
    "When customizing configuration of pipeline optimization, you need to ensure that the option `save_db` of [VectorIndexConfig](../autoapi/autointent/configs/VectorIndexConfig.html#autointent.configs.VectorIndexConfig) is set to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff74d65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:23:25.183561Z",
     "iopub.status.busy": "2024-12-18T13:23:25.182726Z",
     "iopub.status.idle": "2024-12-18T13:23:25.186711Z",
     "shell.execute_reply": "2024-12-18T13:23:25.186155Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import VectorIndexConfig\n",
    "\n",
    "# isn't compatible with \"right-after-optimization\" inference\n",
    "vector_index_config = VectorIndexConfig(save_db=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e7f0c7",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "2. **RAM usage.**\n",
    "\n",
    "You can optimize RAM usage by saving all modules to file system. Just set the following options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25580322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:23:25.188837Z",
     "iopub.status.busy": "2024-12-18T13:23:25.188446Z",
     "iopub.status.idle": "2024-12-18T13:23:25.191638Z",
     "shell.execute_reply": "2024-12-18T13:23:25.191079Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import LoggingConfig\n",
    "\n",
    "logging_config = LoggingConfig(dump_modules=True, clear_ram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2aede8",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Load from File System\n",
    "\n",
    "Firstly, your auto-configuration run should dump modules into file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec7b4c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:23:25.193427Z",
     "iopub.status.busy": "2024-12-18T13:23:25.193217Z",
     "iopub.status.idle": "2024-12-18T13:23:28.344412Z",
     "shell.execute_reply": "2024-12-18T13:23:28.343664Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from autointent import Dataset, Pipeline\n",
    "from autointent.configs import LoggingConfig, VectorIndexConfig\n",
    "\n",
    "dataset = Dataset.from_hub(\"AutoIntent/clinc150_subset\")\n",
    "pipeline = Pipeline.default_optimizer(multilabel=False)\n",
    "dump_dir = Path(\"my_dumps\")\n",
    "pipeline.set_config(LoggingConfig(dump_dir=dump_dir, dump_modules=True, clear_ram=True))\n",
    "pipeline.set_config(VectorIndexConfig(save_db=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136dabc2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Secondly, after optimization finished, you need to save the auto-configuration results to file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f80b8ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:23:28.347008Z",
     "iopub.status.busy": "2024-12-18T13:23:28.346622Z",
     "iopub.status.idle": "2024-12-18T13:24:45.788782Z",
     "shell.execute_reply": "2024-12-18T13:24:45.788059Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "context = pipeline.fit(dataset)\n",
    "context.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bbd279",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "This command saves all results to the run's directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efdd37c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:24:45.791290Z",
     "iopub.status.busy": "2024-12-18T13:24:45.790844Z",
     "iopub.status.idle": "2024-12-18T13:24:45.795497Z",
     "shell.execute_reply": "2024-12-18T13:24:45.794845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/runner/work/AutoIntent/AutoIntent/docs/source/user_guides/runs/dull_duck_12-18-2024_13-23-28')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_directory = context.logging_config.dirpath\n",
    "run_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8d48a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "After that, you can load pipeline for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc3df60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:24:45.797562Z",
     "iopub.status.busy": "2024-12-18T13:24:45.797136Z",
     "iopub.status.idle": "2024-12-18T13:24:46.635029Z",
     "shell.execute_reply": "2024-12-18T13:24:46.634296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pipeline = Pipeline.load(run_directory)\n",
    "loaded_pipeline.predict([\"hello, world!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd90d15",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## That's all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ddc1e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:24:46.637455Z",
     "iopub.status.busy": "2024-12-18T13:24:46.637028Z",
     "iopub.status.idle": "2024-12-18T13:24:47.867412Z",
     "shell.execute_reply": "2024-12-18T13:24:47.866560Z"
    }
   },
   "outputs": [],
   "source": [
    "# [you didn't see it]\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(dump_dir)\n",
    "\n",
    "for file in Path.cwd().glob(\"vector_db*\"):\n",
    "    shutil.rmtree(file)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
