autointent.metrics.retrieval_precision_intersecting
===================================================

.. py:function:: autointent.metrics.retrieval_precision_intersecting(query_labels, candidates_labels, k = None)

   Calculate the precision at position k for the intersecting labels.

   Precision at position :math:`k` for intersecting labels is calculated as:

   .. math::

       \text{Precision@k}_{\text{intersecting}} = \frac{1}{N} \sum_{i=1}^N
       \frac{\sum_{j=1}^k \mathbb{1} \left( y_{\text{query},i} \cdot y_{\text{candidates},i,j} > 0 \right)}{k}

   where:
   - :math:`N` is the total number of queries,
   - :math:`y_{\text{query},i}` is the one-hot encoded label vector for the :math:`i`-th query,
   - :math:`y_{\text{candidates},i,j}` is the one-hot encoded label vector of the :math:`j`-th
   candidate for the :math:`i`-th query,
   - :math:`k` is the number of top candidates considered,
   - :math:`\mathbb{1}(\text{condition})` is the indicator function that equals 1 if the
   condition is true and 0 otherwise.

   :param query_labels: For each query, this list contains its class labels
   :param candidates_labels: For each query, these lists contain class labels of items ranked by a retrieval model
    (from most to least relevant)
   :param k: Number of top items to consider for each query
   :return: Score of the retrieval metric

