{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf4a2f1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Inference Pipeline\n",
    "\n",
    "After you configured optimal pipeline with AutoIntent, you probably want to test its power on some new data! There are several options:\n",
    "\n",
    "- use it right after optimization\n",
    "- save to file system and then load\n",
    "\n",
    "## Right After\n",
    "\n",
    "Here's the basic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfdd5a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:16:15.479674Z",
     "iopub.status.busy": "2024-12-18T13:16:15.479199Z",
     "iopub.status.idle": "2024-12-18T13:17:23.322332Z",
     "shell.execute_reply": "2024-12-18T13:17:23.321591Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/.cache/pypoetry/virtualenvs/autointent-FDypUDHQ-py3.10/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autointent import Dataset, Pipeline\n",
    "\n",
    "dataset = Dataset.from_hub(\"AutoIntent/clinc150_subset\")\n",
    "pipeline = Pipeline.default_optimizer(multilabel=False)\n",
    "context = pipeline.fit(dataset)\n",
    "pipeline.predict([\"hello, world!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b835fc",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "There are several caveats.\n",
    "\n",
    "1. **Save vector databse.**\n",
    "\n",
    "When customizing configuration of pipeline optimization, you need to ensure that the option `save_db` of [VectorIndexConfig](../autoapi/autointent/configs/VectorIndexConfig.html#autointent.configs.VectorIndexConfig) is set to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a7edf94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:17:23.325271Z",
     "iopub.status.busy": "2024-12-18T13:17:23.324387Z",
     "iopub.status.idle": "2024-12-18T13:17:23.328352Z",
     "shell.execute_reply": "2024-12-18T13:17:23.327670Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import VectorIndexConfig\n",
    "\n",
    "# isn't compatible with \"right-after-optimization\" inference\n",
    "vector_index_config = VectorIndexConfig(save_db=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79611c31",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "2. **RAM usage.**\n",
    "\n",
    "You can optimize RAM usage by saving all modules to file system. Just set the following options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa61c9c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:17:23.330553Z",
     "iopub.status.busy": "2024-12-18T13:17:23.330101Z",
     "iopub.status.idle": "2024-12-18T13:17:23.333497Z",
     "shell.execute_reply": "2024-12-18T13:17:23.332830Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import LoggingConfig\n",
    "\n",
    "logging_config = LoggingConfig(dump_modules=True, clear_ram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7433609",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Load from File System\n",
    "\n",
    "Firstly, your auto-configuration run should dump modules into file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6587dac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:17:23.335696Z",
     "iopub.status.busy": "2024-12-18T13:17:23.335230Z",
     "iopub.status.idle": "2024-12-18T13:17:24.934536Z",
     "shell.execute_reply": "2024-12-18T13:17:24.933929Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from autointent import Dataset, Pipeline\n",
    "from autointent.configs import LoggingConfig, VectorIndexConfig\n",
    "\n",
    "dataset = Dataset.from_hub(\"AutoIntent/clinc150_subset\")\n",
    "pipeline = Pipeline.default_optimizer(multilabel=False)\n",
    "dump_dir = Path(\"my_dumps\")\n",
    "pipeline.set_config(LoggingConfig(dump_dir=dump_dir, dump_modules=True, clear_ram=True))\n",
    "pipeline.set_config(VectorIndexConfig(save_db=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2419cbc",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Secondly, after optimization finished, you need to save the auto-configuration results to file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b87cae94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:17:24.936966Z",
     "iopub.status.busy": "2024-12-18T13:17:24.936487Z",
     "iopub.status.idle": "2024-12-18T13:18:48.666250Z",
     "shell.execute_reply": "2024-12-18T13:18:48.665551Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "context = pipeline.fit(dataset)\n",
    "context.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9346a647",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "This command saves all results to the run's directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2a5753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:18:48.668821Z",
     "iopub.status.busy": "2024-12-18T13:18:48.668404Z",
     "iopub.status.idle": "2024-12-18T13:18:48.672641Z",
     "shell.execute_reply": "2024-12-18T13:18:48.672153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/runner/work/AutoIntent/AutoIntent/docs/source/user_guides/runs/dull_duck_12-18-2024_13-17-24')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_directory = context.logging_config.dirpath\n",
    "run_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e754795",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "After that, you can load pipeline for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a07a4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:18:48.674711Z",
     "iopub.status.busy": "2024-12-18T13:18:48.674339Z",
     "iopub.status.idle": "2024-12-18T13:18:49.738805Z",
     "shell.execute_reply": "2024-12-18T13:18:49.738143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pipeline = Pipeline.load(run_directory)\n",
    "loaded_pipeline.predict([\"hello, world!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68da888",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## That's all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50923ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:18:49.741101Z",
     "iopub.status.busy": "2024-12-18T13:18:49.740702Z",
     "iopub.status.idle": "2024-12-18T13:18:50.844034Z",
     "shell.execute_reply": "2024-12-18T13:18:50.843439Z"
    }
   },
   "outputs": [],
   "source": [
    "# [you didn't see it]\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(dump_dir)\n",
    "\n",
    "for file in Path.cwd().glob(\"vector_db*\"):\n",
    "    shutil.rmtree(file)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
