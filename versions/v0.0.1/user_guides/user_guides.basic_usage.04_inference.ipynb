{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8fd462d",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Inference Pipeline\n",
    "\n",
    "After you configured optimal pipeline with AutoIntent, you probably want to test its power on some new data! There are several options:\n",
    "\n",
    "- use it right after optimization\n",
    "- save to file system and then load\n",
    "\n",
    "## Right After\n",
    "\n",
    "Here's the basic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0984a2b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:16:14.355287Z",
     "iopub.status.busy": "2024-12-18T13:16:14.354794Z",
     "iopub.status.idle": "2024-12-18T13:17:21.252059Z",
     "shell.execute_reply": "2024-12-18T13:17:21.251243Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/.cache/pypoetry/virtualenvs/autointent-FDypUDHQ-py3.10/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autointent import Dataset, Pipeline\n",
    "\n",
    "dataset = Dataset.from_hub(\"AutoIntent/clinc150_subset\")\n",
    "pipeline = Pipeline.default_optimizer(multilabel=False)\n",
    "context = pipeline.fit(dataset)\n",
    "pipeline.predict([\"hello, world!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1208b05e",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "There are several caveats.\n",
    "\n",
    "1. **Save vector databse.**\n",
    "\n",
    "When customizing configuration of pipeline optimization, you need to ensure that the option `save_db` of [VectorIndexConfig](../autoapi/autointent/configs/VectorIndexConfig.html#autointent.configs.VectorIndexConfig) is set to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17adaff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:17:21.255203Z",
     "iopub.status.busy": "2024-12-18T13:17:21.254522Z",
     "iopub.status.idle": "2024-12-18T13:17:21.258854Z",
     "shell.execute_reply": "2024-12-18T13:17:21.258207Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import VectorIndexConfig\n",
    "\n",
    "# isn't compatible with \"right-after-optimization\" inference\n",
    "vector_index_config = VectorIndexConfig(save_db=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1140e5d",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "2. **RAM usage.**\n",
    "\n",
    "You can optimize RAM usage by saving all modules to file system. Just set the following options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709c96b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:17:21.260821Z",
     "iopub.status.busy": "2024-12-18T13:17:21.260604Z",
     "iopub.status.idle": "2024-12-18T13:17:21.263892Z",
     "shell.execute_reply": "2024-12-18T13:17:21.263330Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import LoggingConfig\n",
    "\n",
    "logging_config = LoggingConfig(dump_modules=True, clear_ram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd7e136",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Load from File System\n",
    "\n",
    "Firstly, your auto-configuration run should dump modules into file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7808d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:17:21.265929Z",
     "iopub.status.busy": "2024-12-18T13:17:21.265552Z",
     "iopub.status.idle": "2024-12-18T13:17:22.333520Z",
     "shell.execute_reply": "2024-12-18T13:17:22.332718Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from autointent import Dataset, Pipeline\n",
    "from autointent.configs import LoggingConfig, VectorIndexConfig\n",
    "\n",
    "dataset = Dataset.from_hub(\"AutoIntent/clinc150_subset\")\n",
    "pipeline = Pipeline.default_optimizer(multilabel=False)\n",
    "dump_dir = Path(\"my_dumps\")\n",
    "pipeline.set_config(LoggingConfig(dump_dir=dump_dir, dump_modules=True, clear_ram=True))\n",
    "pipeline.set_config(VectorIndexConfig(save_db=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b575a339",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Secondly, after optimization finished, you need to save the auto-configuration results to file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f022192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:17:22.335953Z",
     "iopub.status.busy": "2024-12-18T13:17:22.335734Z",
     "iopub.status.idle": "2024-12-18T13:18:42.329049Z",
     "shell.execute_reply": "2024-12-18T13:18:42.328352Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "context = pipeline.fit(dataset)\n",
    "context.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4fcdc",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "This command saves all results to the run's directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5294553a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:18:42.331718Z",
     "iopub.status.busy": "2024-12-18T13:18:42.331258Z",
     "iopub.status.idle": "2024-12-18T13:18:42.335978Z",
     "shell.execute_reply": "2024-12-18T13:18:42.335317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/runner/work/AutoIntent/AutoIntent/docs/source/user_guides/runs/dull_duck_12-18-2024_13-17-22')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_directory = context.logging_config.dirpath\n",
    "run_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69fbba7",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "After that, you can load pipeline for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "619f7f48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:18:42.338172Z",
     "iopub.status.busy": "2024-12-18T13:18:42.337810Z",
     "iopub.status.idle": "2024-12-18T13:18:43.227855Z",
     "shell.execute_reply": "2024-12-18T13:18:43.227123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pipeline = Pipeline.load(run_directory)\n",
    "loaded_pipeline.predict([\"hello, world!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847995b2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## That's all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b130e87d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:18:43.230274Z",
     "iopub.status.busy": "2024-12-18T13:18:43.229843Z",
     "iopub.status.idle": "2024-12-18T13:18:44.516536Z",
     "shell.execute_reply": "2024-12-18T13:18:44.515698Z"
    }
   },
   "outputs": [],
   "source": [
    "# [you didn't see it]\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(dump_dir)\n",
    "\n",
    "for file in Path.cwd().glob(\"vector_db*\"):\n",
    "    shutil.rmtree(file)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
