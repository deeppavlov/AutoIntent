{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "302d03c4",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Pipeline Auto Configuration (AutoML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c7a732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:15:01.243050Z",
     "iopub.status.busy": "2024-12-18T13:15:01.242851Z",
     "iopub.status.idle": "2024-12-18T13:15:05.036930Z",
     "shell.execute_reply": "2024-12-18T13:15:05.036261Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/.cache/pypoetry/virtualenvs/autointent-FDypUDHQ-py3.10/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from autointent import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654afe72",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "In this tutorial we will walk through pipeline auto configuration process.\n",
    "\n",
    "Let us use small subset of popular `clinc150` dataset for the demonstation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a66063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:15:05.039557Z",
     "iopub.status.busy": "2024-12-18T13:15:05.039002Z",
     "iopub.status.idle": "2024-12-18T13:15:06.842984Z",
     "shell.execute_reply": "2024-12-18T13:15:06.842354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['utterance', 'label'],\n",
       "     num_rows: 60\n",
       " }),\n",
       " 'oos': Dataset({\n",
       "     features: ['utterance', 'label'],\n",
       "     num_rows: 10\n",
       " })}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autointent import Dataset\n",
    "\n",
    "dataset = Dataset.from_hub(\"AutoIntent/clinc150_subset\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0edb946c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:15:06.845172Z",
     "iopub.status.busy": "2024-12-18T13:15:06.844774Z",
     "iopub.status.idle": "2024-12-18T13:15:06.848845Z",
     "shell.execute_reply": "2024-12-18T13:15:06.848329Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'does acero in maplewood allow reservations', 'label': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6077b5",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Search Space\n",
    "\n",
    "AutoIntent provides default search spaces for multi-label and single-label classification problems. One can utilize them by constructing [Pipeline](../autoapi/autointent/Pipeline.html#autointent.Pipeline) with factory [default_optimizer](../autoapi/autointent/Pipeline.html#autointent.Pipeline.default_optimizer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb7b3d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:15:06.850850Z",
     "iopub.status.busy": "2024-12-18T13:15:06.850474Z",
     "iopub.status.idle": "2024-12-18T13:15:06.859819Z",
     "shell.execute_reply": "2024-12-18T13:15:06.859327Z"
    }
   },
   "outputs": [],
   "source": [
    "multiclass_pipeline = Pipeline.default_optimizer(multilabel=False)\n",
    "multilabel_pipeline = Pipeline.default_optimizer(multilabel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27969752",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "One can explore its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca9ce9ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:15:06.861732Z",
     "iopub.status.busy": "2024-12-18T13:15:06.861350Z",
     "iopub.status.idle": "2024-12-18T13:15:06.867809Z",
     "shell.execute_reply": "2024-12-18T13:15:06.867293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'metric': 'retrieval_hit_rate_intersecting',\n",
      "  'node_type': 'embedding',\n",
      "  'search_space': [{'embedder_name': ['deepvk/USER-bge-m3'],\n",
      "                    'k': [10],\n",
      "                    'module_name': 'retrieval'}]},\n",
      " {'metric': 'scoring_roc_auc',\n",
      "  'node_type': 'scoring',\n",
      "  'search_space': [{'k': [3],\n",
      "                    'module_name': 'knn',\n",
      "                    'weights': ['uniform', 'distance', 'closest']},\n",
      "                   {'module_name': 'linear'}]},\n",
      " {'metric': 'decision_accuracy',\n",
      "  'node_type': 'decision',\n",
      "  'search_space': [{'module_name': 'threshold', 'thresh': [0.5]},\n",
      "                   {'module_name': 'adaptive'}]}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from autointent.utils import load_default_search_space\n",
    "\n",
    "search_space = load_default_search_space(multilabel=True)\n",
    "pprint(search_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f60d9b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Search space is allowed to customize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e08680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:15:06.869883Z",
     "iopub.status.busy": "2024-12-18T13:15:06.869510Z",
     "iopub.status.idle": "2024-12-18T13:15:06.872499Z",
     "shell.execute_reply": "2024-12-18T13:15:06.871972Z"
    }
   },
   "outputs": [],
   "source": [
    "search_space[1][\"search_space\"][0][\"k\"] = [1, 3]\n",
    "custom_pipeline = Pipeline.from_search_space(search_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57869c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "See tutorial [02_search_space_configuration](../user_guides/user_guides.advanced.02_search_space_configuration.py) on how the search space is structured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf48d42",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Embedder Settings\n",
    "\n",
    "[Embedder](../autoapi/autointent/Embedder.html#autointent.Embedder) is one of the key components of AutoIntent. It affects both the quality of the resulting classifier and the efficiency of the auto configuration process.\n",
    "\n",
    "To select embedding models for your optimization, you need to customize search space ([02_search_space_configuration](../user_guides/user_guides.advanced.02_search_space_configuration.py)). Here, we will observe settings affecting efficiency.\n",
    "\n",
    "Several options are customizable via [EmbedderConfig](../autoapi/autointent/configs/EmbedderConfig.html#autointent.configs.EmbedderConfig). Defaults are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ec605dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:15:06.874581Z",
     "iopub.status.busy": "2024-12-18T13:15:06.874206Z",
     "iopub.status.idle": "2024-12-18T13:15:06.877362Z",
     "shell.execute_reply": "2024-12-18T13:15:06.876822Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import EmbedderConfig\n",
    "\n",
    "embedder_config = EmbedderConfig(\n",
    "    batch_size=32,\n",
    "    max_length=None,\n",
    "    use_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeda6dd",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "To set selected settings, method [set_config](../autoapi/autointent/Pipeline.html#autointent.Pipeline.set_config) is provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a24824ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:15:06.879356Z",
     "iopub.status.busy": "2024-12-18T13:15:06.878962Z",
     "iopub.status.idle": "2024-12-18T13:15:06.881842Z",
     "shell.execute_reply": "2024-12-18T13:15:06.881313Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_pipeline.set_config(embedder_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c93ada",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Vector Index Settings\n",
    "\n",
    "[VectorIndex](../autoapi/autointent/context/vector_index_client/VectorIndex.html#autointent.context.vector_index_client.VectorIndex) is one of the key utilities of AutoIntent. During the auto-configuration process, lots of retrieval is used. By modifying [VectorIndexConfig](../autoapi/autointent/configs/VectorIndexConfig.html#autointent.configs.VectorIndexConfig) you can select whether to save built vector index into file system and where to save it.\n",
    "\n",
    "Default options are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afecfeb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:15:06.883780Z",
     "iopub.status.busy": "2024-12-18T13:15:06.883401Z",
     "iopub.status.idle": "2024-12-18T13:15:06.886447Z",
     "shell.execute_reply": "2024-12-18T13:15:06.885905Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import VectorIndexConfig\n",
    "\n",
    "vector_index_config = VectorIndexConfig(db_dir=None, save_db=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43895eee",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "- `db_dir=None` tells AutoIntent to store intermediate files in a current working directory\n",
    "- `save_db=False` tells AutoIntent to clear all the files after auto configuration is finished\n",
    "\n",
    "These settings can be applied in a familiar way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd4e216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:15:06.888448Z",
     "iopub.status.busy": "2024-12-18T13:15:06.887979Z",
     "iopub.status.idle": "2024-12-18T13:15:06.890730Z",
     "shell.execute_reply": "2024-12-18T13:15:06.890208Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_pipeline.set_config(vector_index_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b902866c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Logging Settings\n",
    "\n",
    "The important thing is what assets you want to save during the pipeline auto-configuration process. You can control it with [LoggingConfig](../autoapi/autointent/configs/LoggingConfig.html#autointent.configs.LoggingConfig). Default settings are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12479606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:15:06.892745Z",
     "iopub.status.busy": "2024-12-18T13:15:06.892372Z",
     "iopub.status.idle": "2024-12-18T13:15:06.895706Z",
     "shell.execute_reply": "2024-12-18T13:15:06.895176Z"
    }
   },
   "outputs": [],
   "source": [
    "from autointent.configs import LoggingConfig\n",
    "\n",
    "logging_config = LoggingConfig(run_name=None, dirpath=None, dump_dir=None, dump_modules=False, clear_ram=False)\n",
    "custom_pipeline.set_config(logging_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4823cc38",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Complete Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbe0ba02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T13:15:06.897655Z",
     "iopub.status.busy": "2024-12-18T13:15:06.897273Z",
     "iopub.status.idle": "2024-12-18T13:16:11.142791Z",
     "shell.execute_reply": "2024-12-18T13:16:11.141816Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autointent import Dataset, Pipeline\n",
    "from autointent.configs import EmbedderConfig, LoggingConfig, VectorIndexConfig\n",
    "from autointent.utils import load_default_search_space\n",
    "\n",
    "# load data\n",
    "dataset = Dataset.from_hub(\"AutoIntent/clinc150_subset\")\n",
    "\n",
    "# customize search space\n",
    "search_space = load_default_search_space(multilabel=False)\n",
    "\n",
    "# make pipeline\n",
    "custom_pipeline = Pipeline.from_search_space(search_space)\n",
    "\n",
    "# custom settings\n",
    "embedder_config = EmbedderConfig()\n",
    "vector_index_config = VectorIndexConfig()\n",
    "logging_config = LoggingConfig()\n",
    "\n",
    "custom_pipeline.set_config(embedder_config)\n",
    "custom_pipeline.set_config(vector_index_config)\n",
    "custom_pipeline.set_config(logging_config)\n",
    "\n",
    "# start auto-configuration\n",
    "custom_pipeline.fit(dataset)\n",
    "\n",
    "# inference\n",
    "custom_pipeline.predict([\"hello world!\"])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
